{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### python script applied and purpose of the run \n",
    "# script_run = general_pipline_4D.py\n",
    "# purpose = preprocessing session 211011 with pipeline from 220220s\n",
    "\n",
    "### provided paths = data_path, saving_path and n2v model path\n",
    "path_to_data = '/home/mpg08/aicha.hajiali/TLI_project/TLI_data/preprocessed/2022/T4/220209/SyNRA_old2/'\n",
    "save_path = '/home/mpg08/aicha.hajiali/TLI_project/TLI_data/preprocessed/2022/T4/220209/SyNRA_old2/compile/'\n",
    "model_path = '/home/mpg08/aicha.hajiali/TLI_project/preprocessing/n2v/models/'\n",
    "\n",
    "### basename of output tiff files\n",
    "output_name = 'SyNRA_GFP_220209_brain2.2_LP40_P36.tif'\n",
    "\n",
    "### data filtering parameters = name(group), channel names,subset\n",
    "group = 'SyNRA_GFP_220209_brain2.2_LP40_P36'\n",
    "ch_names = ['GFP', 'red']  ## if the images has one channel then also specify here (e.g =GFP)\n",
    "reg_subset = (0,60,325,600,300,650)  ##Z,Y,X slicing. In case no subset required, type 0,0\n",
    "# reg_subset is not used in current 4D_pipeline\n",
    "\n",
    "### preprocessing steps to apply\n",
    "steps = ['compile','preshift', 'postshift', 'ants']\n",
    "#all means ['compile','preshift', 'trim','postshift', 'ants', 'n2v', 'clahe', 'mask', 'segment']\n",
    "\n",
    "### rotation and image_flip (not implemented yet)\n",
    "# rotat_O = 6\n",
    "# Flip = false\n",
    "\n",
    "### files metadata\n",
    "xy_pixel = 0.0764616\n",
    "z_pixel = 0.4\n",
    "\n",
    "### clahe parameters =\n",
    "clipLimit = 1\n",
    "kernel_size = (45, 45)\n",
    "\n",
    "### n2v paramters =\n",
    "model_name = 'n2v_3D_v6'\n",
    "\n",
    "### registration sequence\n",
    "reference_last = False\n",
    "ants_ref_no = 35\n",
    "ref_reset = 50\n",
    "\n",
    "### registration parameters\n",
    "save_pre_shift = True\n",
    "sigma = 5\n",
    "drift_corr = ['Rigid', 'Affine', 'SyNRA']\n",
    "metric = ['meansquares', 'mattes', 'CC']\n",
    "grad_step = 0.2\n",
    "flow_sigma = 3\n",
    "total_sigma = 0\n",
    "aff_sampling = 32\n",
    "syn_sampling = 32\n",
    "reg_iterations = (80,40,10)\n",
    "aff_iterations = (2100,1200,1200,10)\n",
    "aff_shrink_factors = (6,4,2,1)\n",
    "aff_smoothing_sigmas = (3,2,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages and define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "# We import all our dependencies.\n",
    "import argparse\n",
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np \n",
    "import tifffile as tif\n",
    "from detect_delimiter import detect\n",
    "from n2v.models import N2V\n",
    "import ants\n",
    "from skimage.registration import phase_cross_correlation as corr\n",
    "import csv\n",
    "import psutil\n",
    "import gc\n",
    "from scipy import ndimage, spatial, stats\n",
    "from sklearn import metrics\n",
    "from skimage.filters import gaussian, threshold_otsu, median\n",
    "from tqdm import tqdm\n",
    "import operator\n",
    "import Neurosetta as neu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These three functions to read txt info file (here not implemented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem_use():\n",
    "    print('memory usage')\n",
    "    print('cpu_percent', psutil.cpu_percent())\n",
    "    print(dict(psutil.virtual_memory()._asdict()))\n",
    "    print('percentage of used RAM', psutil.virtual_memory().percent)\n",
    "    print('percentage of available memory', psutil.virtual_memory().available * 100 / psutil.virtual_memory().total)\n",
    "\n",
    "def str2bool(v):\n",
    "    \"\"\"this function convert str to corresponding boolean value\"\"\"\n",
    "    options = (\"yes\", \"true\", \"t\", 'y', 'no','false', 'n','f')\n",
    "    if v.lower() in options:\n",
    "        return str(v).lower() in (\"yes\", \"true\", \"t\", \"1\")\n",
    "    else:\n",
    "        return v\n",
    "\n",
    "def txt2dict(path):\n",
    "    start_time = timer()\n",
    "    print('getting info from', path)\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if line[0] == '#':\n",
    "            lines.remove(line)\n",
    "    for ind, line in enumerate(lines):\n",
    "        if '#' in line:\n",
    "            lines[ind] = line[0:line.index('#')]\n",
    "        elif '\\n' in line:\n",
    "            lines[ind] = line.replace('\\n','')\n",
    "    for line in lines:\n",
    "        if line == '':\n",
    "            lines.remove(line)\n",
    "    delimiter = detect(lines[0])\n",
    "    print(len(lines),'lines found in txt_file with', delimiter, 'as the delimiter')\n",
    "    try:\n",
    "        for i in [0]:\n",
    "            lines = [item.strip().rsplit(delimiter, 2) for item in lines]\n",
    "            input_txt = {item[0].strip(): item[1].strip() for item in lines}\n",
    "    except:\n",
    "        print('failed to read txt_file')\n",
    "    for key, val in input_txt.items():\n",
    "        if ',' in val:\n",
    "            try:\n",
    "                input_txt[key] = tuple(map(int, val.split(',')))\n",
    "            except:\n",
    "                try:\n",
    "                    input_txt[key] = [item.strip() for item in val.split(',')]\n",
    "                except:\n",
    "                    pass\n",
    "        else:\n",
    "            try:\n",
    "                input_txt[key] = float(val)\n",
    "            except:\n",
    "                input_txt[key] = str2bool(val)    \n",
    "    ### adding some default parameters if missing in info_txt\n",
    "    if 'sigma' not in input_txt.keys():\n",
    "        input_txt['sigma'] = 0\n",
    "    if 'steps' not in input_txt.keys():\n",
    "        input_txt['steps'] = ['all']    \n",
    "    if 'reg_subset' not in input_txt.keys():\n",
    "        input_txt['reg_subset'] = [0,0]\n",
    "    if 'metric' not in input_txt.keys():\n",
    "        input_txt['metric'] = 'mattes'\n",
    "    if 'check_ch' not in input_txt.keys():\n",
    "        input_txt['check_ch'] = input_txt['ch_names'][0]\n",
    "    # if 'double_register' not in input_txt.keys():\n",
    "    #     input_txt['double_register'] = False\n",
    "    #### reasign un-recognized parameters\n",
    "    if type(input_txt['ch_names']) != list:\n",
    "        input_txt['ch_names'] = [input_txt['ch_names']]\n",
    "    if type(input_txt['drift_corr']) != list:\n",
    "        input_txt['drift_corr'] = [input_txt['drift_corr']]\n",
    "    if type(input_txt['steps']) == str:\n",
    "        input_txt['steps'] = [input_txt['steps'].lower()]\n",
    "    elif type(input_txt['steps']) == tuple:\n",
    "        input_txt['steps'] = [s.lower() for s in input_txt['steps']]\n",
    "    if 'all' in input_txt['steps']:\n",
    "        input_txt['steps'] = ['compile','preshift', 'trim','postshift', 'ants', 'n2v', 'clahe', 'mask', 'segment']\n",
    "    if 'check_ch' not in input_txt['ch_names']:\n",
    "        print('channel defined for similarity_check not recognized, so %s used' %input_txt['ch_names'][0])\n",
    "        input_txt['check_ch'] = input_txt['ch_names'][0]\n",
    "    parameters = {'grad_step':0.2, 'flow_sigma':3, 'total_sigma':0,\n",
    "                'aff_sampling':32, 'aff_random_sampling_rate':0.2, \n",
    "                'syn_sampling':32, 'reg_iterations':(40,20,0), \n",
    "                'aff_iterations':(2100,1200,1200,10), \n",
    "                'aff_shrink_factors':(6,4,2,1), \n",
    "                'aff_smoothing_sigmas':(3,2,1,0)}\n",
    "    for para in parameters.keys():\n",
    "        if para in input_txt.keys():\n",
    "            pass\n",
    "        else:\n",
    "            input_txt[para] = parameters[para]\n",
    "    if 'ants_ref_st' not in input_txt.keys():\n",
    "        input_txt['ants_ref_st'] = 0    \n",
    "    print(input_txt)\n",
    "    print('reading_text runtime', timer()-start_time)\n",
    "    return input_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_names(path, group_by='', order=True, nested_files=False, criteria='tif'):\n",
    "    \"\"\"returns a list of all files' names in the given directory and its sub-folders\n",
    "    the list can be filtered based on the 'group_by' str provided\n",
    "    the files_list is sorted in reverse if the order is set to True. \n",
    "    The first element of the list is used later as ref\"\"\"\n",
    "    start_time = timer()\n",
    "    if os.path.isfile(path):\n",
    "        file_list = [path]\n",
    "    else:\n",
    "        file_list = []\n",
    "        if nested_files == False:\n",
    "            file_list = [os.path.join(path, f) for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "        else:\n",
    "            for path, subdirs, files in os.walk(path):\n",
    "                for name in files:\n",
    "                    file_list.append(os.path.join(path, name))\n",
    "        file_list = [file for file in file_list if group_by in file]\n",
    "        file_list = [file for file in file_list if criteria in file]\n",
    "        file_list.sort(reverse=order)    \n",
    "    print('files_list runtime', timer()-start_time)\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_limits(img, limit=0, ddtype='uint16'):\n",
    "    # for i in tqdm(range(1), desc = 'img_limit'):\n",
    "    max_limits = {'uint8': 255, 'uint16': 65530}\n",
    "    img = img - img.min()        \n",
    "    if limit == 0:\n",
    "        limit = img.max()\n",
    "    if limit > max_limits[ddtype]:\n",
    "        limit = max_limits[ddtype]\n",
    "        # print('the limit provided is larger than alocated dtype. limit reassigned as appropriate', limit)\n",
    "    img = img/img.max()\n",
    "    img = img*limit\n",
    "    img = img.astype(ddtype)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_convert(image, ch_names):\n",
    "    \"\"\"deinterleave the image into dictionary of two channels\"\"\"\n",
    "    # for i in tqdm(range(1), desc = 'split_convert'):\n",
    "    start_time = timer()\n",
    "    image_ch = {}\n",
    "    for ind, ch in enumerate(ch_names):\n",
    "        image_ch[ch] = image[ind::len(ch_names)]\n",
    "    if len(ch_names) > 1:\n",
    "        image_ch[ch_names[-1]] = median(image_ch[ch_names[-1]])\n",
    "    for ch, img in image_ch.items():\n",
    "        image_ch[ch] = img_limits(img, limit=0)\n",
    "    print('split_convert runtime', timer()-start_time)\n",
    "    return image_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_to_4D(files_list, ch_names=[''], \n",
    "                save=True, save_path='', save_file='', \n",
    "                xy_pixel=1, z_pixel=1, ddtype='uint16'):\n",
    "    \"\"\"\n",
    "    read files_list, load the individual 3D_img tifffiles, \n",
    "    and convert them into a dict of 4D-arrays of the identified ch\n",
    "    has the option of saving is as 8uint image\n",
    "    \"\"\"\n",
    "    start_time = timer()\n",
    "    image_4D = {ch:[] for ch in ch_names}\n",
    "    files_list.sort()\n",
    "    for file in tqdm(files_list, desc = 'compiling_files'):\n",
    "        image = tif.imread(file)\n",
    "        image = split_convert(image, ch_names=ch_names)\n",
    "        for ch in ch_names:\n",
    "            image_4D[ch].append(image[ch])\n",
    "    z_dim = min([len(img) for img in image_4D[ch_names[0]]])\n",
    "    print(image_4D.keys(), type(image_4D[ch_names[-1]]), len(image_4D[ch_names[-1]]))\n",
    "    for ch in ch_names:\n",
    "        print('compiling the', ch, 'channel')\n",
    "        image_4D[ch] = [stack[0:z_dim] for stack in image_4D[ch]]\n",
    "        image_4D[ch] = np.array(image_4D[ch])\n",
    "        for tim in tqdm(range(len(image_4D[ch])), desc = 'setting img_limits'):\n",
    "            if image_4D[ch][tim].min()!= 0 or image_4D[ch][tim].dtype != ddtype:\n",
    "                image_4D[ch][tim] = img_limits(image_4D[ch][tim], limit=0, ddtype=ddtype)    \n",
    "    if save == True:\n",
    "        if save_path[-1] != '/':\n",
    "            save_path += '/'\n",
    "        if save_file == '':\n",
    "            name1 = os.path.basename(files_list[0])\n",
    "            name2 = os.path.basename(files_list[1])\n",
    "            for s in name1:\n",
    "                if s in name2:\n",
    "                    save_file += s\n",
    "                else:\n",
    "                    break\n",
    "        for ch, img in image_4D.items():\n",
    "            save_name = save_path+'4D_'+ch+'_'+save_file\n",
    "            if os.path.splitext(save_name)[-1] not in ['.tif','.tiff']:\n",
    "                save_name += '.tif'\n",
    "            save_image(save_name, img, xy_pixel=xy_pixel, z_pixel=z_pixel)\n",
    "    print('files_to_4D runtime', timer()-start_time)\n",
    "    return image_4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_subset(img, subset):\n",
    "    print('subsetting the image')\n",
    "    try:\n",
    "        subset_img = img[subset[0]:subset[1],subset[2]:subset[3],subset[4]:subset[5]]\n",
    "    except:\n",
    "        print('failed to subset image')\n",
    "    return subset_img\n",
    "\n",
    "def rot_flip(img, flip, angle=0):\n",
    "    vert = ['vertical', 'vertically', 2, -1]\n",
    "    hort = ['horizontally', 'horizontal', 1]\n",
    "    if flip in vert:\n",
    "        flipped = img[:,:,::-1]\n",
    "        print('flipped image vertically')\n",
    "    elif flip in hort:\n",
    "        flipped = img[:,::-1,:]\n",
    "        print('flipped image horizontally')\n",
    "    else:\n",
    "        flipped = img.copy()\n",
    "    \n",
    "    if len(flipped.shape) == 2:\n",
    "        flipped = ndimage.rotate(flipped, angle, reshape=False)\n",
    "        print('rotated image by', angle)\n",
    "    else:\n",
    "        for ind, sli in enumerate(flipped):\n",
    "            flipped[ind] = ndimage.rotate(sli, angle, reshape=False)\n",
    "        print('rotated image by', angle)\n",
    "    return flipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(name, image, xy_pixel=0.0764616, z_pixel=0.4):\n",
    "    \"\"\"save provided image by name with provided xy_pixel, and z_pixel resolution as metadata\"\"\"\n",
    "    if len(image.shape) == 3:\n",
    "        dim = 'ZYX'\n",
    "    elif len(image.shape) == 4:\n",
    "        dim = 'TZYX'\n",
    "    if image.dtype != 'uint16': ###this part to be omitted later\n",
    "        print('image type is not uint16')\n",
    "        image = image.astype('uint16')\n",
    "    tif.imwrite(name, image, imagej=True, dtype=image.dtype, resolution=(1./xy_pixel, 1./xy_pixel),\n",
    "                metadata={'spacing': z_pixel, 'unit': 'um', 'finterval': 1/10,'axes': dim})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two functions for phase correlation, but no longer used because Neurosetta is now used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_corr(fixed, moving, sigma):\n",
    "    if fixed.shape > moving.shape:\n",
    "        print('fixed image is larger than moving', fixed.shape, moving.shape)\n",
    "        fixed = fixed[tuple(map(slice, moving.shape))]\n",
    "        print('fixed image resized to', fixed.shape)\n",
    "    elif fixed.shape < moving.shape:\n",
    "        print('fixed image is smaller than moving', fixed.shape, moving.shape)\n",
    "        moving = moving[tuple(map(slice, fixed.shape))]\n",
    "        print('moving image resized to', moving.shape)\n",
    "    fixed = gaussian(fixed, sigma=sigma)\n",
    "    moving = gaussian(moving, sigma=sigma)\n",
    "    print('applying phase correlation')\n",
    "    try:\n",
    "        for i in [0]:\n",
    "            shift, error, diffphase = corr(fixed, moving)\n",
    "    except:\n",
    "        for i in [0]:\n",
    "            shift, error, diffphase = np.zeros(len(moving)), 0, 0\n",
    "            print(\"couldn't perform PhaseCorr, so shift was casted as zeros\")\n",
    "    return shift\n",
    "\n",
    "def phase_corr_4D(image, sigma, xy_pixel=1, \n",
    "                  z_pixel=1, ch_names=[1], \n",
    "                  ref_ch=-1,                      \n",
    "                  save=True, save_path='',\n",
    "                  save_file='', save_shifts=True):\n",
    "    if isinstance(image, dict) == False:\n",
    "        image = {ch_names[0]:image}\n",
    "    pre_shifts = {}\n",
    "    if len(ch_names) == 1:\n",
    "        ref_ch = ch_names[0]\n",
    "    else:\n",
    "        try:\n",
    "            ref_ch = ch_names[ref_ch]\n",
    "        except:\n",
    "            ref_ch = ch_names[-1]\n",
    "    ref_im = image[ref_ch]\n",
    "    current_shift = [0 for i in ref_im[0].shape]\n",
    "    print('initial shift of 0', current_shift)\n",
    "    print(len(ref_im[1:]), ref_im[1].shape)\n",
    "    for ind in tqdm(np.arange(len(ref_im[1:]))) :\n",
    "        pre_shifts[ind+1] = phase_corr(ref_im[ind], ref_im[ind+1], sigma) \n",
    "        current_shift = [sum(x) for x in zip(current_shift, pre_shifts[ind+1])] \n",
    "        print(pre_shifts[ind+1], current_shift)\n",
    "        print('applying preshift on timepoint', ind+1, 'with current pre_shift', current_shift)\n",
    "        for ch, img in image.items(): \n",
    "            image[ch][ind] = ndimage.shift(img[ind], current_shift) \n",
    "    if save == True:\n",
    "        for ch, img in image.items():\n",
    "            save_name = str(save_path+'PhaseCorr_'+ch+'_'+save_file)\n",
    "            if '.tif' not in save_name:\n",
    "                save_name += '.tif'\n",
    "            save_image(save_name, img, xy_pixel=xy_pixel, z_pixel=z_pixel)   \n",
    "    if save_shifts == True:\n",
    "        shift_file = save_path+\"PhaseCorr_shifts.csv\"\n",
    "        with open(shift_file, 'w', newline='') as csvfile:\n",
    "            fieldnames = ['timepoint', 'phase_shift']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for timepoint, shift in pre_shifts.items():\n",
    "                writer.writerow({'timepoint' : timepoint+1, 'phase_shift' : shift})\n",
    "        csvfile.close()\n",
    "    return image, pre_shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_similarity(ref, image):\n",
    "    try:\n",
    "        for i in [1]:\n",
    "            image = image.numpy()\n",
    "            ref = ref.numpy()\n",
    "    except:\n",
    "        pass\n",
    "    check = sum(metrics.pairwise.cosine_similarity(image.ravel().reshape(1,-1), \n",
    "                           ref.ravel().reshape(1,-1)))[0]\n",
    "    # print('check_similarity of image to ref is', check)\n",
    "    return check\n",
    "\n",
    "def similarity_4D(image_4D, save=True, save_path='', save_file=''):\n",
    "    start_time = timer()\n",
    "    similairties = {1:1}\n",
    "    for t in tqdm(np.arange(len(image_4D[1:])), desc='cosine_sim for timepoint'):\n",
    "        img_t = image_4D[t]\n",
    "        similairties[t+2] = check_similarity(img_t, image_4D[t+1])\n",
    "    if save == True:\n",
    "        if save_file == '':\n",
    "            save_file = \"phase_similarity_check.csv\"\n",
    "        checks_file = save_path+save_file\n",
    "        if '.csv' not in checks_file:\n",
    "            checks_file +='.csv'\n",
    "        with open(checks_file, 'w', newline='') as csvfile:\n",
    "            fieldnames = ['timepoint', 'cosine_similarity']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for timepoint, check in similairties.items():\n",
    "                writer.writerow({'timepoint' : timepoint, 'cosine_similarity' : check})\n",
    "        csvfile.close()\n",
    "        print('finished measuring similarity check', timer()-start_time)\n",
    "    return similairties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def N2V_predict(model_name, model_path, xy_pixel=1, z_pixel=1, image=0, file='', save=True, save_path='', save_file=''):\n",
    "    \"\"\"apply N2V prediction on image based on provided model\n",
    "    if save is True, save predicted image with provided info\"\"\"\n",
    "    if file != '':\n",
    "        image = tif.imread(file)\n",
    "    file_name = os.path.basename(file)\n",
    "    model = N2V(config=None, name=model_name, basedir=model_path)\n",
    "    predict = model.predict(image, axes='ZYX', n_tiles=None)\n",
    "    if predict.min() != 0:\n",
    "        predict = img_limits(predict, limit=0)\n",
    "    if save == True:\n",
    "        if save_file == '':\n",
    "            save_name = str(save_path+'N2V_'+file_name)\n",
    "        else:\n",
    "            save_name = str(save_path+'N2V_'+save_file)\n",
    "        if '.tif' not in save_name:\n",
    "            save_name +='.tif'\n",
    "        save_image(save_name, predict, xy_pixel=xy_pixel, z_pixel=z_pixel)\n",
    "    return predict\n",
    "\n",
    "def N2V_4D(image_4D, model_name, model_path, xy_pixel=1, z_pixel=1, save=True, save_path='', save_file=''):\n",
    "    for ind, stack in enumerate(image_4D):\n",
    "        image_4D[ind] = N2V_predict(image=stack,\n",
    "                                    model_name=model_name, \n",
    "                                    model_path=model_path, \n",
    "                                    save=False)\n",
    "    if save == True:\n",
    "        if save_file == '':\n",
    "            save_name = str(save_path+'N2V_4D.tif')\n",
    "        else:\n",
    "            save_name = str(save_path+'N2V_'+save_file)\n",
    "        if '.tif' not in save_name:\n",
    "            save_name +='.tif'\n",
    "        save_image(save_name, image_4D, xy_pixel=xy_pixel, z_pixel=z_pixel)\n",
    "    return image_4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_clahe(kernel_size, xy_pixel=1, z_pixel=1, image=0, file='', clipLimit=1, save=True, save_path='', save_file=''):\n",
    "    \"\"\"apply Clahe on image based on provided kernel_size and clipLimit\n",
    "    if save is True, save predicted image with provided info\"\"\"\n",
    "    if file != '':\n",
    "        image = tif.imread(file)\n",
    "    if image.min()<0:\n",
    "        image = (image - image.min())\n",
    "    image = image.astype('uint16')\n",
    "    print(image.dtype)\n",
    "    file_name = os.path.basename(file)\n",
    "    image_clahe= np.empty(image.shape)\n",
    "    clahe_mask = cv.createCLAHE(clipLimit=clipLimit, tileGridSize=kernel_size)\n",
    "    for ind, slice in enumerate(image):\n",
    "        image_clahe[ind] = clahe_mask.apply(slice)\n",
    "        image_clahe[ind] = cv.threshold(image_clahe[ind], \n",
    "                            thresh=np.percentile(image_clahe[ind], 95), \n",
    "                            maxval=image_clahe[ind].max(), \n",
    "                            type= cv.THRESH_TOZERO)[1]\n",
    "    if image_clahe.min() != 0:\n",
    "        image_clahe = img_limits(image_clahe, limit=0)\n",
    "    if save == True:\n",
    "        if save_file == '':\n",
    "            save_name = save_path+'clahe_'+file_name\n",
    "        else:\n",
    "            save_name = save_path+'clahe_'+save_file\n",
    "        if '.tif' not in save_name:\n",
    "            save_name += '.tif'\n",
    "        save_image(save_name, image_clahe, xy_pixel=xy_pixel, z_pixel=z_pixel)\n",
    "    return image_clahe\n",
    "\n",
    "def clahe_4D(image_4D, kernel_size, clipLimit=1, xy_pixel=1, z_pixel=1, save=True, save_path='', save_file=''):\n",
    "    for ind, stack in enumerate(image_4D):\n",
    "        image_4D[ind] = apply_clahe(image=stack,\n",
    "                                    kernel_size=kernel_size, \n",
    "                                    clipLimit=clipLimit, \n",
    "                                    save=False)\n",
    "    if save == True:\n",
    "        if save_file == '':\n",
    "            save_name = str(save_path+'clahe_4D.tif')\n",
    "        else:\n",
    "            save_name = str(save_path+'clahe_'+save_file)\n",
    "        if '.tif' not in save_name:\n",
    "            save_name +='.tif'\n",
    "        save_image(save_name, image_4D, xy_pixel=xy_pixel, z_pixel=z_pixel)\n",
    "    return image_4D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these two functions to create masked images, but are not used because Neurosetta is implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_image(volume, return_mask = False ,sig = 2):\n",
    "    \"\"\"\n",
    "    Create a binary mask from a 2 or 3-dimensional np.array.\n",
    "    Method normalizes the image, converts it to greyscale, then applies gaussian bluring (kernel width set to 2 by default, can be changed with sig parameter).\n",
    "    This is followed by thresholding the image using the isodata method and returning a binary mask. \n",
    "    Parameters\n",
    "    ----------\n",
    "    image           np.array\n",
    "                    np.array of an image (2 or 3D)\n",
    "    return_mask     bool\n",
    "                    If False (default), the mask is subtracted from the original image. If True, a boolian array is returned, of the shape of the original image, as a mask. \n",
    "    sig             Int\n",
    "                    kernel width for gaussian smoothing. set to 2 by default.\n",
    "    Returns\n",
    "    -------\n",
    "    mask            np.array\n",
    "                    Returns a binary np.array of equal shape to the original image, labeling the masked area.\n",
    "    \"\"\"\n",
    "    for i in tqdm(range(1), desc = '3D_mask'):\n",
    "        start_time = timer()\n",
    "        image = volume.copy()\n",
    "        # if input image is 2D...\n",
    "        image = image.astype('float32')\n",
    "        # normalize to the range 0-1\n",
    "        image -= image.min()\n",
    "        image /= image.max()\n",
    "        # blur and grayscale before thresholding\n",
    "        blur = gaussian(image, sigma=sig)\n",
    "        # perform adaptive thresholding\n",
    "        t = threshold_otsu(blur.ravel())\n",
    "        mask = blur > t\n",
    "        # convert to bool\n",
    "        mask = np.array(mask, dtype=bool)\n",
    "        print('mask_image runtime', timer()-start_time)\n",
    "    if return_mask == False:\n",
    "        image[mask==False] = 0\n",
    "        return image\n",
    "    else:\n",
    "        return mask\n",
    "\n",
    "def mask_4D(image, xy_pixel=1, z_pixel=1, sig=2, save=True, save_path='', save_file=''):\n",
    "    start_time = timer()\n",
    "    mask = image.copy()\n",
    "    mask_image = image.copy()\n",
    "    for i, img in enumerate(image):\n",
    "        print('calculating mask for stack#', i)\n",
    "        try:\n",
    "            mask[i] = mask_image(img, return_mask=False ,sig=sig)\n",
    "            mask_image[i] = mask_image(img, return_mask=True ,sig=sig)\n",
    "        except:\n",
    "            mask[i] = mask[i]\n",
    "            mask_image[i] = mask_image[i]\n",
    "        mask[i] = img_limits(mask[i], limit=255, ddtype='uint16')\n",
    "    if save == True:\n",
    "        if save_file == '':\n",
    "            save_name = save_path+'masked_image.tif'\n",
    "            mask_name = save_path+'mask.tif'\n",
    "        else:\n",
    "            mask_name = save_path+'mask_'+save_file\n",
    "            save_name = save_path+'image_mask_'+save_file\n",
    "        if '.tif' not in save_name:\n",
    "            save_name += '.tif'\n",
    "        save_image(mask_name, mask, xy_pixel=xy_pixel, z_pixel=z_pixel)\n",
    "        save_image(save_name, mask_image, xy_pixel=xy_pixel, z_pixel=z_pixel)\n",
    "    print('mask_4D runtime', timer()-start_time)\n",
    "    return mask, mask_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is about Antspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def antspy_regi(ref, img, drift_corr, metric='mattes',\n",
    "                reg_iterations=(40,20,0), \n",
    "                aff_iterations=(2100,1200,1200,10), \n",
    "                aff_shrink_factors=(6,4,2,1), \n",
    "                aff_smoothing_sigmas=(3,2,1,0),\n",
    "                grad_step=0.2, flow_sigma=3, total_sigma=0,\n",
    "                aff_sampling=32, syn_sampling=32):\n",
    "\n",
    "    \"\"\"claculate drift of image from ref using Antspy with provided drift_corr\"\"\"\n",
    "    try:\n",
    "        for i in [1]:\n",
    "            fixed= ants.from_numpy(np.float32(ref.copy()))\n",
    "            moving= ants.from_numpy(np.float32(img.copy()))\n",
    "    except:\n",
    "        for i in [1]:\n",
    "            fixed= ref.copy()\n",
    "            moving= img.copy()\n",
    "    # shift = ants.registration(fixed, moving, type_of_transform=drift_corr,\n",
    "    #                             aff_metric=metric, syn_metric=metric)            \n",
    "    shift = ants.registration(fixed, moving, type_of_transform=drift_corr, \n",
    "                              aff_metric=metric, syn_metric=metric,\n",
    "                              reg_iterations=(reg_iterations[0],reg_iterations[1],reg_iterations[2]), \n",
    "                              aff_iterations=(aff_iterations[0],aff_iterations[1],aff_iterations[2],aff_iterations[3]), \n",
    "                              aff_shrink_factors=(aff_shrink_factors[0],aff_shrink_factors[1],aff_shrink_factors[2],aff_shrink_factors[3]), \n",
    "                              aff_smoothing_sigmas=(aff_smoothing_sigmas[0],aff_smoothing_sigmas[1],aff_smoothing_sigmas[2],aff_smoothing_sigmas[3]),\n",
    "                              grad_step=grad_step, flow_sigma=flow_sigma, total_sigma=total_sigma,\n",
    "                              aff_sampling=aff_sampling, syn_sampling=syn_sampling)\n",
    "    try:\n",
    "        ref = ref.numpy().astype('uint16')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        img = img.numpy().astype('uint16')\n",
    "    except:\n",
    "        pass\n",
    "    # print(type(ref), type(img))\n",
    "    del fixed, moving\n",
    "    return shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def antspy_drift(ref, img, shift, check=False):\n",
    "    \"\"\"shifts image based on ref and provided shift\"\"\"\n",
    "    try:\n",
    "        ref = ref.numpy()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        img = img.numpy()\n",
    "    except:\n",
    "        pass\n",
    "    ref= ants.from_numpy(np.float32(ref))\n",
    "    img= ants.from_numpy(np.float32(img))\n",
    "    vol_shifted = ants.apply_transforms(ref, img, transformlist=shift)\n",
    "    ref = ref.numpy().astype('uint16')\n",
    "    img = img.numpy().astype('uint16')\n",
    "    vol_shifted = vol_shifted.numpy().astype('uint16')\n",
    "    # print((vol_shifted == img).all())\n",
    "    if check == True:\n",
    "        pre_check = check_similarity(ref, img)\n",
    "        post_check = check_similarity(ref, vol_shifted)\n",
    "        print('similarity_check', pre_check, 'improved to', post_check)\n",
    "        if (pre_check - post_check) > 0.1:\n",
    "            vol_shifted = img.copy()\n",
    "            print('similarity_check was smaller after shift, so shift was ignored:', pre_check, '>>', post_check)\n",
    "    print(shift, (vol_shifted == img).all())\n",
    "    return vol_shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ants_channels(ref, image, drift_corr='Rigid',  xy_pixel=1, \n",
    "                        z_pixel=1, ch_names=[''], ref_ch=-1,\n",
    "                        metric='mattes',\n",
    "                        reg_iterations=(40,20,0), \n",
    "                        aff_iterations=(2100,1200,1200,10), \n",
    "                        aff_shrink_factors=(6,4,2,1), \n",
    "                        aff_smoothing_sigmas=(3,2,1,0),\n",
    "                        grad_step=0.2, flow_sigma=3, total_sigma=0,\n",
    "                        aff_sampling=32, syn_sampling=3,  \n",
    "                        check_ch='',                       \n",
    "                        save=True, save_path='',save_file=''):\n",
    "    \"\"\"calculate and apply shift on both channels of image based on ref, which is dictionary of two channels.\n",
    "    if save is True, save shifted channels individually with provided info\"\"\"\n",
    "    shift = antspy_regi(ref[ch_names[ref_ch]], image[ch_names[ref_ch]], drift_corr, metric,\n",
    "                        reg_iterations=reg_iterations, \n",
    "                        aff_iterations=aff_iterations, \n",
    "                        aff_shrink_factors=aff_shrink_factors, \n",
    "                        aff_smoothing_sigmas=aff_smoothing_sigmas,\n",
    "                        grad_step=grad_step, flow_sigma=flow_sigma, \n",
    "                        total_sigma=total_sigma,\n",
    "                        aff_sampling=aff_sampling, \n",
    "                        syn_sampling=syn_sampling)\n",
    "    shifted = {}\n",
    "    for ch, img in image.items():\n",
    "        shifted[ch]= antspy_drift(ref[ch],img,shift=shift['fwdtransforms'],check=False)\n",
    "    if check_ch in image.keys():\n",
    "        pre_check = check_similarity(ref[check_ch], image[check_ch])\n",
    "        post_check = check_similarity(ref[check_ch], shifted[check_ch])        \n",
    "        if (pre_check - post_check) <= 0.1:\n",
    "            print('similarity_check', pre_check, 'improved to', post_check)\n",
    "        else:\n",
    "            print('similarity_check was smaller after shift, so it was ignored:', pre_check, '>>', post_check)\n",
    "            shifted = image.copy()\n",
    "    else:\n",
    "        print(check_ch, 'not a recognized ch in image')\n",
    "    for ch, img in shifted.items():\n",
    "        if img.min() != 0:\n",
    "            shifted[ch] = img_limits(img, ddtype='uint16')\n",
    "        if save == True:\n",
    "            save_name = str(save_path+drift_corr+'_'+ch+'_'+save_file)\n",
    "            if '.tif' not in save_name:\n",
    "                save_name += '.tif'\n",
    "            save_image(save_name, shifted[ch], xy_pixel=xy_pixel, z_pixel=z_pixel)\n",
    "    return shifted, shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ants_4D(image, drift_corr,  xy_pixel=1, \n",
    "                  z_pixel=1, ch_names=[1], ref_t=0,\n",
    "                  ref_ch=-1, metric='mattes',\n",
    "                  reg_iterations=(40,20,0), \n",
    "                  aff_iterations=(2100,1200,1200,10), \n",
    "                  aff_shrink_factors=(6,4,2,1), \n",
    "                  aff_smoothing_sigmas=(3,2,1,0),\n",
    "                  grad_step=0.2, flow_sigma=3, total_sigma=0,\n",
    "                  aff_sampling=32, syn_sampling=3,  \n",
    "                  check_ch='',                       \n",
    "                  save=True, save_path='',save_file=''):\n",
    "    \"\"\"\"\"\"\n",
    "    start_time = timer()\n",
    "    if isinstance(image, dict) == False:\n",
    "        image = {ch_names[0]:image}\n",
    "    s_range = len(image[ch_names[ref_ch]])\n",
    "    scope = np.arange(0,ref_t)\n",
    "    scope = np.concatenate((scope, np.arange(ref_t,s_range)))\n",
    "    print('ants seq for 4D regi',scope)\n",
    "    if ref_t== -1:\n",
    "        ref_t= len(image[ch_names[-1]])-1\n",
    "        \n",
    "    raw_sim_checks = [1]\n",
    "    for i in tqdm(np.arange(len(image[check_ch])-1), desc='similarity_check'):\n",
    "        raw_sim_checks.append(check_similarity(image[check_ch][i], image[check_ch][i+1]))\n",
    "    fixed = {ch:img[ref_t].copy() for ch, img in image.items()}\n",
    "    shifts = [0]\n",
    "    desc = 'AntsPy_'+drift_corr\n",
    "    for i in tqdm(scope, desc=desc):\n",
    "        moving = {ch:img[i].copy() for ch, img in image.items()}\n",
    "        shifted, shift = apply_ants_channels(fixed, moving, drift_corr=drift_corr,  \n",
    "                                            xy_pixel=xy_pixel, \n",
    "                                            z_pixel=z_pixel, ch_names=ch_names, \n",
    "                                            ref_ch=ref_ch,\n",
    "                                            metric=metric,\n",
    "                                            reg_iterations=reg_iterations, \n",
    "                                            aff_iterations=aff_iterations, \n",
    "                                            aff_shrink_factors=aff_shrink_factors, \n",
    "                                            aff_smoothing_sigmas=aff_smoothing_sigmas,\n",
    "                                            grad_step=grad_step, flow_sigma=flow_sigma, \n",
    "                                            total_sigma=total_sigma,\n",
    "                                            aff_sampling=aff_sampling, \n",
    "                                            syn_sampling=syn_sampling,  \n",
    "                                            check_ch=check_ch,                       \n",
    "                                            save=False)\n",
    "        shifts.append(shift['fwdtransforms'])\n",
    "        for ch in ch_names:\n",
    "            image[ch][i] = shifted[ch] \n",
    "            # print('last step',(image[ch][i] == shifted[ch]).all())\n",
    "            if image[ch][i].min() != 0:\n",
    "                image[ch][i] = img_limits(image[ch][i], ddtype='uint16')\n",
    "        del shifted, moving, shift\n",
    "\n",
    "    sim_checks = [1]\n",
    "    for i in tqdm(np.arange(len(image[check_ch])-1), desc='similarity_check'):\n",
    "        sim_checks.append(check_similarity(image[check_ch][i], image[check_ch][i+1]))\n",
    "\n",
    "    if save == True:\n",
    "        for ch, img in image.items():\n",
    "            save_name = str(save_path+drift_corr+'_'+ch+'_'+save_file)\n",
    "            if '.tif' not in save_name:\n",
    "                save_name += '.tif'\n",
    "            save_image(save_name, img, xy_pixel=xy_pixel, z_pixel=z_pixel)   \n",
    "\n",
    "        shift_file = save_path+drift_corr+'AntsShifts_'+save_file+'.csv'\n",
    "        shift_file = shift_file.replace('.tif','')\n",
    "        with open(shift_file, 'w', newline='') as csvfile:\n",
    "            fieldnames = ['timepoint', 'shift_mat']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for timepoint, shift in enumerate(shifts):\n",
    "                writer.writerow({'timepoint' : timepoint+1, 'shift_mat' : shift})\n",
    "        csvfile.close()    \n",
    "\n",
    "        check_file = save_path+drift_corr+'ANTsCheck_'+save_file+\".csv\"\n",
    "        check_file = check_file.replace('.tif','')\n",
    "        with open(check_file, 'w', newline='') as csvfile1:\n",
    "            fieldnames = ['timepoint', 'original','after_shift']\n",
    "            writer = csv.DictWriter(csvfile1, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for timepoint, check in enumerate(sim_checks):\n",
    "                writer.writerow({'timepoint' : timepoint+1, 'original':raw_sim_checks[timepoint],'after_shift' : check})\n",
    "        csvfile1.close()    \n",
    "    print('ants_round runtime', timer()-start_time)  \n",
    "    del shifts, sim_checks\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### compiling the single 3D tif files to 4D_image, or reading 4D_image(s)\n",
    "start_time = timer()\n",
    "try:\n",
    "    file_4D = output_name\n",
    "except:    \n",
    "    file_4D = group.split('_')[0]+'.tif'\n",
    "if os.path.isdir(path_to_data):\n",
    "    files_list = get_file_names(path_to_data, \n",
    "                                group_by=group, \n",
    "                                order=reference_last)\n",
    "    print('the first 5 files (including ref) are', files_list[0:5])\n",
    "    if 'compile' in steps:\n",
    "        # loading raw skimage files into 4D array and saving raw 4D\n",
    "        print('compiling 3D image_files into dict of 4D_images of specified channels')\n",
    "        image_4D = files_to_4D(files_list, ch_names=ch_names, save=True, \n",
    "                            save_path=save_path, \n",
    "                            save_file='raw_'+file_4D, \n",
    "                            xy_pixel=xy_pixel, \n",
    "                            z_pixel=z_pixel, \n",
    "                            ddtype='uint16')\n",
    "    else:\n",
    "        temp = ch_names.copy()\n",
    "        temp.sort()\n",
    "        image_4D = {ch:tif.imread(files_list[ind]) for ind, ch in enumerate(temp)} \n",
    "elif os.path.isfile(path_to_data):\n",
    "    image_4D = {ch_names[0]:tif.imread(path_to_data)}\n",
    "    files_list = [i for i in np.arange(len(image_4D))]  ### I don't remember why I needed this line\n",
    "    if file_4D == '':\n",
    "        file_4D = os.path.basename(path_to_data)\n",
    "        file_4D = file_4D.split('_')[0]+'.tif'    \n",
    "print('finished reading and compiling images', timer()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### initial registration of images using phase_correlation on red (last) channel using Neurosetta\n",
    "if 'preshift' in steps:\n",
    "    start_time = timer()\n",
    "    print('applying preshift')\n",
    "    neuron = neu.Neuron(image_4D[ch_names[-1]])\n",
    "    shifts = neu.shifts(neuron)\n",
    "    for ch, img in image_4D.items():\n",
    "        for ind, sta in img:\n",
    "            current_shift = sum(shifts[:ind])\n",
    "            image_4D[ch][ind] = ndimage.shift(sta, current_shift)\n",
    "    sa_name = save_path+'Phase_'+ch+'_'+output_name\n",
    "    save_image(sa_name, image_4D[ch], xy_pixel=xy_pixel, z_pixel=z_pixel)   \n",
    "    del neuron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### optional deletion of last quater of slices in Z_dim of each 3D image\n",
    "#### this is to reduce the run time for Ants a little bit\n",
    "if 'trim' in steps:\n",
    "    start_time = timer()\n",
    "    trim = int((3*image_4D[ch_names[-1]].shape[1])/4)\n",
    "    print('image size before trimming is', image_4D[ch_names[-1]].shape)\n",
    "    print('trimming all images in Z dim to 0:', trim)\n",
    "    for ch, img in image_4D.items():\n",
    "        image_4D[ch] = img[:,0:trim]\n",
    "    print('image size after trimming is', image_4D[ch_names[-1]].shape)\n",
    "    print('finished trimming images', timer()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### applying Ants registration based on the last (red) channel\n",
    "if 'ants' in steps:\n",
    "    start_time = timer()\n",
    "    ref_t = ants_ref_no\n",
    "    if isinstance(ref_t, int) == False or ref_t < 0 or ref_t > len(image_4D[ch_names[-1]]):\n",
    "        ref_t = 0\n",
    "    for i, drift_t in enumerate(drift_corr):\n",
    "        ants_step = str(i+1)\n",
    "        try:\n",
    "            metric_t = metric[i]\n",
    "        except:\n",
    "            for i in [0]:\n",
    "                print('optimization metric not recognized. mattes used instead')\n",
    "                metric_t = 'mattes'\n",
    "        image_4D = apply_ants_4D(image_4D, \n",
    "                                drift_corr=drift_t,  \n",
    "                                xy_pixel=xy_pixel, \n",
    "                                z_pixel=z_pixel, \n",
    "                                ch_names=ch_names, \n",
    "                                ref_t=ref_t,\n",
    "                                ref_ch=-1, \n",
    "                                metric=metric_t,\n",
    "                                reg_iterations=reg_iterations, \n",
    "                                aff_iterations=aff_iterations, \n",
    "                                aff_shrink_factors=aff_shrink_factors, \n",
    "                                aff_smoothing_sigmas=aff_smoothing_sigmas,\n",
    "                                grad_step=grad_step, \n",
    "                                flow_sigma=flow_sigma, \n",
    "                                total_sigma=total_sigma,\n",
    "                                aff_sampling=aff_sampling, \n",
    "                                syn_sampling=syn_sampling, \n",
    "                                check_ch=ch_names[0],                       \n",
    "                                save=True, \n",
    "                                save_path=save_path,\n",
    "                                save_file=ants_step+'_'+file_4D)\n",
    "        print('finished ants run with', drift_t)\n",
    "    print('finished antspy registration', timer()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'postshift' in steps:\n",
    "    start_time = timer()\n",
    "    if 'neurons' not in locals():\n",
    "        neurons = {1: image_4D[ch_names[0]]}\n",
    "    ref_t = ants_ref_no\n",
    "    if isinstance(ref_t, int) == False or ref_t < 0 or ref_t > len(image_4D[ch_names[-1]]):\n",
    "        ref_t = 0\n",
    "    for l, neuron in neurons.items():\n",
    "        image = image_4D.copy()\n",
    "        image[ch_names[0]] = neuron\n",
    "        for i, drift_t in enumerate(drift_corr):\n",
    "            ants_step = str(i+1)\n",
    "            try:\n",
    "                metric_t = metric[i]\n",
    "            except:\n",
    "                for i in [0]:\n",
    "                    print('optimization metric not recognized. mattes used instead')\n",
    "                    metric_t = 'mattes'\n",
    "            image_4D = apply_ants_4D(image, \n",
    "                                    drift_corr=drift_t,  \n",
    "                                    xy_pixel=xy_pixel, \n",
    "                                    z_pixel=z_pixel, \n",
    "                                    ch_names=ch_names, \n",
    "                                    ref_t=ref_t,\n",
    "                                    ref_ch=0, ### this is the main defference between ants and postshift\n",
    "                                    metric=metric_t,\n",
    "                                    reg_iterations=reg_iterations, \n",
    "                                    aff_iterations=aff_iterations, \n",
    "                                    aff_shrink_factors=aff_shrink_factors, \n",
    "                                    aff_smoothing_sigmas=aff_smoothing_sigmas,\n",
    "                                    grad_step=grad_step, \n",
    "                                    flow_sigma=flow_sigma, \n",
    "                                    total_sigma=total_sigma,\n",
    "                                    aff_sampling=aff_sampling, \n",
    "                                    syn_sampling=syn_sampling,\n",
    "                                    check_ch=ch_names[0],                       \n",
    "                                    save=True, \n",
    "                                    save_path=save_path,\n",
    "                                    save_file='neuron'+str(l)+'_'+ants_step+'_'+file_4D)\n",
    "            print('finished postshift on neuron %i run with' %l, drift_t)\n",
    "            del image\n",
    "    print('total ruuntime of postshift', timer()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##The parts for N2V, clahe, mask and segment are to be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
