{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do:\n",
    "- test similarity scikit image (Niko)\n",
    "- add scope to antspy registration (Aicha) DONE!\n",
    "   Also, moved the concatentation and sim_check of the registered files to the Antspy func\n",
    "- change channel 2 shifted assignment to shift 'warpmoveout' (Aicha) DONE!\n",
    "\n",
    "##Testing:\n",
    "- stage 2: T4, T5\n",
    "    - sessions: 220219, 220221\n",
    "- stage 1: T4, T5 \n",
    "    - sessions: 211011, 220124"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ants_method = ['SyNRA']\n",
    "path_to_data = '/home/mpg08/aicha.hajiali/TLI_project/TLI_data/2022/T4/220209/'\n",
    "save_path = '/home/mpg08/aicha.hajiali/TLI_project/TLI_data/preprocessed/2022/T4/220209/SyNRA_old5/'\n",
    "group_by = '209_brain2.2_LP40_P36'\n",
    "ch_names = ['GFP', 'red']\n",
    "save_name = '220209_brain2.2_LP40_P36'\n",
    "csv_name = '_220209_SyNRA_antspy.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages and define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ants\n",
    "from skimage import io, filters\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "import tifffile as tif\n",
    "import cv2 as cv\n",
    "from sklearn import metrics\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_names(path, group_by='', order=True, nested_files=False, criteria='tif'):\n",
    "    \"\"\"\n",
    "    returns a list of all files' names in the given directory and its sub-folders\n",
    "    the list can be filtered based on the 'group_by' str provided\n",
    "    the files_list is sorted in reverse if the order is set to True. \n",
    "    The first element of the list is used later as ref\n",
    "    \"\"\"\n",
    "    if os.path.isfile(path):\n",
    "        file_list = [path]\n",
    "    else:\n",
    "        file_list = []\n",
    "        if nested_files == False:\n",
    "            file_list = [os.path.join(path, f) for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "        else:\n",
    "            for path, subdirs, files in os.walk(path):\n",
    "                for name in files:\n",
    "                    file_list.append(os.path.join(path, name))\n",
    "        file_list = [file for file in file_list if group_by in file]\n",
    "        file_list = [file for file in file_list if criteria in file]\n",
    "        file_list.sort(reverse=order)    \n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_convert(image, ch_names):\n",
    "    \"\"\"deinterleave the image into dictionary of two channels\"\"\"\n",
    "    # for i in tqdm(range(1), desc = 'split_convert'):\n",
    "    start_time = timer()\n",
    "    image_ch = {}\n",
    "    for ind, ch in enumerate(ch_names):\n",
    "        image_ch[ch] = image[ind::len(ch_names)]\n",
    "    # if len(ch_names) > 1:\n",
    "    #     image_ch[ch_names[-1]] = filters.median(image_ch[ch_names[-1]])\n",
    "    print('split_convert runtime', timer()-start_time)\n",
    "    return image_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_to_4D(files_list, ch_names=[''], \n",
    "                save=True, save_path='', save_file='', \n",
    "                xy_pixel=1, z_pixel=1, ddtype='uint16'):\n",
    "    \"\"\"\n",
    "    read files_list, load the individual 3D_img tifffiles, \n",
    "    and convert them into a dict of 4D-arrays of the identified ch\n",
    "    has the option of saving is as 8uint image\n",
    "    \"\"\"\n",
    "    start_time = timer()\n",
    "    image_4D = {ch:[] for ch in ch_names}\n",
    "    files_list.sort()\n",
    "    for file in tqdm(files_list, desc = 'compiling_files'):\n",
    "        image = tif.imread(file)\n",
    "        image = split_convert(image, ch_names=ch_names)\n",
    "        for ch in ch_names:\n",
    "            image_4D[ch].append(image[ch])\n",
    "    z_dim = min([len(img) for img in image_4D[ch_names[0]]])\n",
    "    print(image_4D.keys(), type(image_4D[ch_names[-1]]), len(image_4D[ch_names[-1]]))\n",
    "    for ch in ch_names:\n",
    "        print('compiling the', ch, 'channel')\n",
    "        image_4D[ch] = [stack[0:z_dim] for stack in image_4D[ch]]\n",
    "        image_4D[ch] = np.array(image_4D[ch])\n",
    "        # for tim in tqdm(range(len(image_4D[ch])), desc = 'setting img_limits'):\n",
    "            # if image_4D[ch][tim].min()!= 0 or image_4D[ch][tim].dtype != ddtype:\n",
    "            #     image_4D[ch][tim] = img_limits(image_4D[ch][tim], limit=0, ddtype=ddtype)    \n",
    "    # if save == True:\n",
    "    #     if save_path[-1] != '/':\n",
    "    #         save_path += '/'\n",
    "    #     if save_file == '':\n",
    "    #         name1 = os.path.basename(files_list[0])\n",
    "    #         name2 = os.path.basename(files_list[1])\n",
    "    #         for s in name1:\n",
    "    #             if s in name2:\n",
    "    #                 save_file += s\n",
    "    #             else:\n",
    "    #                 break\n",
    "    #     for ch, img in image_4D.items():\n",
    "    #         save_name = save_path+'4D_'+ch+'_'+save_file\n",
    "    #         if os.path.splitext(save_name)[-1] not in ['.tif','.tiff']:\n",
    "    #             save_name += '.tif'\n",
    "    #         save_image(save_name, img, xy_pixel=xy_pixel, z_pixel=z_pixel)\n",
    "    print('files_to_4D runtime', timer()-start_time)\n",
    "    return image_4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_similarity(ref, image):\n",
    "    try:\n",
    "        for i in [1]:\n",
    "            image = image.numpy()\n",
    "            ref = ref.numpy()\n",
    "    except:\n",
    "        pass\n",
    "    check = sum(metrics.pairwise.cosine_similarity(image.ravel().reshape(1,-1), \n",
    "                           ref.ravel().reshape(1,-1)))[0]\n",
    "    # print('check_similarity of image to ref is', check)\n",
    "    return check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_4D(image_4D, save=True, save_path='', save_file=''):\n",
    "    start_time = timer()\n",
    "    similairties = {1:1}\n",
    "    for t in tqdm(np.arange(len(image_4D[1:])), desc='cosine_sim for timepoint'):\n",
    "        img_t = image_4D[t]\n",
    "        similairties[t+2] = check_similarity(img_t, image_4D[t+1])\n",
    "    if save == True:\n",
    "        if save_file == '':\n",
    "            save_file = \"phase_similarity_check.csv\"\n",
    "        checks_file = save_path+save_file\n",
    "        if '.csv' not in checks_file:\n",
    "            checks_file +='.csv'\n",
    "        with open(checks_file, 'w', newline='') as csvfile:\n",
    "            fieldnames = ['timepoint', 'cosine_similarity']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for timepoint, check in similairties.items():\n",
    "                writer.writerow({'timepoint' : timepoint, 'cosine_similarity' : check})\n",
    "        csvfile.close()\n",
    "        print('finished measuring similarity check', timer()-start_time)\n",
    "    return similairties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def antspy_drift_corr(img_4D_r, img_4D_g, save_path, save_name, ch_names, group_by, name_shifts, ref_t=0, drift_corr='Rigid'):\n",
    "    \"\"\"\n",
    "    This function takes the folder containing all the files to each channel as an input and drift corrects them.\n",
    "    It uses the files from ch1 to do the drift correction and applies the same correction to ch2.\n",
    "    By default antspy uses the SyN drift correction algorithm.\n",
    "    \n",
    "    path_to_data_ch1: Path to files for ch1 \n",
    "    path_to_data_ch2: Path to files for ch2\n",
    "    savepath: Path to folder where the final files should be saved in\n",
    "    name_ch1: Name for the final file for ch1\n",
    "    name_ch2: Name for the final file for ch2\n",
    "    name_shifts: Name for the file containing the shifts for each volume\n",
    "    \"\"\"\n",
    "            \n",
    "    last = ants.from_numpy(np.float32(filters.median(img_4D_r[-1])))\n",
    "\n",
    "    shifts = []\n",
    "\n",
    "    scope = np.arange(ref_t-1:-1,-1)\n",
    "    scope = np.concatenate((scope, np.arange(ref_t-1,len(img_4D_r)-1)))\n",
    "\n",
    "    for i in tqdm(scope):\n",
    "        \n",
    "        moving_ch1 = ants.from_numpy(np.float32(img_4D_g[i]))\n",
    "        moving_ch2 = ants.from_numpy(np.float32(img_4D_r[i]))\n",
    "        \n",
    "        shift = ants.registration(fixed=last, moving=moving_ch2, type_of_transform=drift_corr)\n",
    "        \n",
    "        vol_shifted_ch1 = ants.apply_transforms(fixed=last, moving=moving_ch1, transformlist=shift['fwdtransforms'])\n",
    "        vol_shifted_ch2 = last = shift['warpedmovout']\n",
    "                \n",
    "        io.imsave(save_path+ch_names[0]+save_name+str(f\"{i+1:03d}\")+'.tif', vol_shifted_ch1.numpy())\n",
    "        io.imsave(save_path+ch_names[1]+save_name+str(f\"{i+1:03d}\")+'.tif', vol_shifted_ch2.numpy())\n",
    "\n",
    "        shifts.append(shift['fwdtransforms'])\n",
    "                \n",
    "        del vol_shifted_ch1, vol_shifted_ch2, shift\n",
    "\n",
    "    gfp_list = get_file_names(path=save_path, group_by=ch_names[0]+save_name, order=False, \n",
    "                                nested_files=False, criteria='tif')\n",
    "    gfp_4D = files_to_4D(files_list=gfp_list, ch_names=[ch_names[0]])\n",
    "    gfp_name = drift_corr+'_4D_'+ch_names[0]+'_'+group_by+'.tif'\n",
    "    tif.imwrite(gfp_name, gfp_4D, imagej=True, resolution=(1./0.076, 1./0.076),\n",
    "                metadata={'spacing': 0.4, 'unit': 'um', 'finterval': 1/10,'axes': 'TZYX'})\n",
    "    for file in gfp_list:\n",
    "        os.remove(file)\n",
    "\n",
    "    red_list = get_file_names(path=save_path, group_by=ch_names[1]+save_name, order=False, \n",
    "                                nested_files=False, criteria='tif')\n",
    "    red_4D = files_to_4D(files_list=red_list, ch_names=[ch_names[1]])\n",
    "    red_name = drift_corr+'_4D_'+ch_names[1]+'_'+group_by+'.tif'\n",
    "    tif.imwrite(red_name, red_4D, imagej=True, resolution=(1./0.076, 1./0.076),\n",
    "                metadata={'spacing': 0.4, 'unit': 'um', 'finterval': 1/10,'axes': 'TZYX'})\n",
    "    for file in red_list:\n",
    "        os.remove(file)\n",
    "\n",
    "    sim_checks = [1]\n",
    "    for i in tqdm(np.arange(len(gfp_4D)-1), desc='similarity_check'):\n",
    "        sim_checks.append(check_similarity(gfp_4D[i], gfp_4D[i+1]))\n",
    "    check_file = save_path+method+'ANTsCheck_'+save_name+\".csv\"\n",
    "    check_file = check_file.replace('.tif','')\n",
    "    with open(check_file, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['timepoint', 'sim_check']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for timepoint, check in enumerate(sim_checks):\n",
    "            writer.writerow({'timepoint' : timepoint+1, 'sim_check' : check})\n",
    "    csvfile.close() \n",
    "\n",
    "    np.savetxt(X=shifts, fname=save_path+name_shifts, delimiter=', ', fmt='% s')\n",
    "    del red_4D, gfp_4D\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list = get_file_names(path=path_to_data, group_by=group_by, order=True, nested_files=False, criteria='tif')\n",
    "image_4D = files_to_4D(files_list=files_list, ch_names=ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in ants_method:\n",
    "    start_time = timer()\n",
    "    name_ch1 = method+'_'+ch_names[0]+'_'\n",
    "    name_ch2 = method+'_'+ch_names[1]+'_'\n",
    "    name_shifts = method+csv_name\n",
    "    antspy_drift_corr(img_4D_r=image_4D[ch_names[0]],\n",
    "                      img_4D_g=image_4D[ch_names[0]], \n",
    "                      save_path=save_path, \n",
    "                      save_name=save_name,\n",
    "                      name_ch1=name_ch1,\n",
    "                      name_ch2=name_ch2,\n",
    "                      name_shifts=name_shifts,\n",
    "                      drift_corr=method)\n",
    "\n",
    "    print(method, ' is done, and it took', timer()-start_time)   \n",
    "\n",
    "print('script is done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
