{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do:\n",
    "- test similarity scikit image (Niko)\n",
    "- add scope to antspy registration (Aicha) DONE!\n",
    "   Also, moved the concatentation and sim_check of the registered files to the Antspy func\n",
    "- change channel 2 shifted assignment to shift 'warpmoveout' (Aicha) DONE!\n",
    "\n",
    "##Testing:\n",
    "- stage 2: T4, T5\n",
    "    - sessions: 220219, 220221\n",
    "- stage 1: T4, T5 \n",
    "    - sessions: 211011, 220124"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ants_method = ['Rigid']\n",
    "path_to_data = '/Users/aichah/Desktop/TLI/data'\n",
    "save_path = '/Users/aichah/Desktop/TLI/data'\n",
    "group_by = '210218'\n",
    "ch_names = ['GFP', 'red']\n",
    "save_name = '210218_LP40_P36'\n",
    "csv_name = '_220209_SyNRA_antspy.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages and define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ants\n",
    "from skimage import io, filters\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "import tifffile as tif\n",
    "from sklearn import metrics\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.datautils as datautils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def antspy_drift_corr(img_4D_r, img_4D_g, ch_names, save_path, save_name, name_shifts, ref_t=0, drift_corr='Rigid'):\n",
    "    \"\"\"\n",
    "    This function takes the folder containing all the files to each channel as an input and drift corrects them.\n",
    "    It uses the files from ch1 to do the drift correction and applies the same correction to ch2.\n",
    "    By default antspy uses the SyN drift correction algorithm.\n",
    "    \n",
    "    path_to_data_ch1: Path to files for ch1 \n",
    "    path_to_data_ch2: Path to files for ch2\n",
    "    savepath: Path to folder where the final files should be saved in\n",
    "    name_ch1: Name for the final file for ch1\n",
    "    name_ch2: Name for the final file for ch2\n",
    "    name_shifts: Name for the file containing the shifts for each volume\n",
    "    \"\"\"\n",
    "\n",
    "    shifts = []\n",
    "\n",
    "    scope = np.arange(ref_t,-1,-1)\n",
    "    scope = np.concatenate((scope, np.arange(ref_t-1,len(img_4D_r)-1)))\n",
    "\n",
    "    for i in tqdm(scope):\n",
    "        if i == ref_t:\n",
    "            io.imsave(save_path+ch_names[0]+'_'+save_name+str(f\"{i+1:03d}\")+'.tif', img_4D_g[i])\n",
    "            io.imsave(save_path+ch_names[1]+'_'+save_name+str(f\"{i+1:03d}\")+'.tif', img_4D_r[i])\n",
    "            last = ants.from_numpy(np.float32(filters.median(img_4D_r[-1])))\n",
    "        else:        \n",
    "            moving_ch1 = ants.from_numpy(np.float32(img_4D_g[i]))\n",
    "            moving_ch2 = ants.from_numpy(np.float32(img_4D_r[i]))\n",
    "            \n",
    "            shift = ants.registration(fixed=last, moving=moving_ch2, type_of_transform=drift_corr)\n",
    "            \n",
    "            vol_shifted_ch1 = ants.apply_transforms(fixed=last, moving=moving_ch1, transformlist=shift['fwdtransforms'])\n",
    "            vol_shifted_ch2 = shift['warpedmovout']\n",
    "            last = shift['warpedmovout'].copy()\n",
    "\n",
    "            vol_shifted_ch1 = (vol_shifted_ch1.numpy()).astype('uint16')\n",
    "            vol_shifted_ch2 = (vol_shifted_ch2.numpy()).astype('uint16')\n",
    "\n",
    "            io.imsave(save_path+ch_names[0]+'_'+save_name+str(f\"{i+1:03d}\")+'.tif', vol_shifted_ch1)\n",
    "            io.imsave(save_path+ch_names[1]+'_'+save_name+str(f\"{i+1:03d}\")+'.tif', vol_shifted_ch2)\n",
    "\n",
    "            shifts.append(shift['fwdtransforms'])\n",
    "                    \n",
    "            del vol_shifted_ch1, vol_shifted_ch2, shift\n",
    "\n",
    "    np.savetxt(X=shifts, fname=save_path+name_shifts, delimiter=', ', fmt='% s')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compiling_files:  10%|█         | 1/10 [00:20<03:04, 20.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_convert runtime 20.408579634999995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compiling_files:  20%|██        | 2/10 [00:40<02:43, 20.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_convert runtime 20.213132924999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compiling_files:  30%|███       | 3/10 [01:01<02:22, 20.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_convert runtime 20.172029369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compiling_files:  40%|████      | 4/10 [01:21<02:00, 20.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_convert runtime 19.678244984000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compiling_files:  50%|█████     | 5/10 [01:41<01:40, 20.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_convert runtime 19.877434121999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compiling_files:  60%|██████    | 6/10 [02:01<01:20, 20.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_convert runtime 20.010500046999994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compiling_files:  70%|███████   | 7/10 [02:20<00:59, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_convert runtime 19.27114945300002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compiling_files:  80%|████████  | 8/10 [02:40<00:39, 19.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_convert runtime 19.349314144999994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compiling_files:  90%|█████████ | 9/10 [02:59<00:19, 19.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_convert runtime 19.466358325000016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compiling_files: 100%|██████████| 10/10 [03:19<00:00, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_convert runtime 19.41588670599998\n",
      "dict_keys(['GFP', 'red']) <class 'list'> 10\n",
      "compiling the GFP channel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling the red channel\n",
      "files_to_4D runtime 200.849550234\n"
     ]
    }
   ],
   "source": [
    "# reading list of 3D images into dictionary of channels as indicated in ch_names, and applying median filter on the last ch\n",
    "image_4D = datautils.read_files(path_to_data, group_by ,compile=True, ch_names=ch_names, \n",
    "                                save=False, save_path='', save_file='', \n",
    "                                xy_pixel=1, z_pixel=1, ddtype='uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cosine_sim for timepoint: 100%|██████████| 9/9 [00:06<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worked\n",
      "finished measuring similarity check 6.240511722000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# measuring the cosine_similarity check of GFP channel before registration\n",
    "pre_checks = datautils.similarity_4D(image_4D[ch_names[0]], save=True, save_path=save_path, save_file='pre_checks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'ants' has no attribute 'from_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5d/tj6rj8cn7_xdplpgkz202g5rnq_4v2/T/ipykernel_9535/149574623.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mname_ch2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mch_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mname_shifts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcsv_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     antspy_drift_corr(img_4D_g=image_4D[ch_names[0]],\n\u001b[0m\u001b[1;32m      7\u001b[0m                       \u001b[0mimg_4D_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_4D\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mch_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                       \u001b[0mch_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mch_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/5d/tj6rj8cn7_xdplpgkz202g5rnq_4v2/T/ipykernel_9535/2416735461.py\u001b[0m in \u001b[0;36mantspy_drift_corr\u001b[0;34m(img_4D_r, img_4D_g, ch_names, save_path, save_name, name_shifts, ref_t, drift_corr)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mref_t\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_4D_r\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mmoving_ch1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_4D_g\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'ants' has no attribute 'from_numpy'"
     ]
    }
   ],
   "source": [
    "# running antspy, saving output into temp 3D files, and then compiling them to 4D and finally deleting the temp 3D files\n",
    "for method in ants_method:\n",
    "    start_time = timer()\n",
    "    name_ch1 = method+'_'+ch_names[0]+'_'\n",
    "    name_ch2 = method+'_'+ch_names[1]+'_'\n",
    "    name_shifts = method+csv_name\n",
    "    antspy_drift_corr(img_4D_g=image_4D[ch_names[0]],\n",
    "                      img_4D_r=image_4D[ch_names[1]], \n",
    "                      ch_names=ch_names,\n",
    "                      save_path=save_path, \n",
    "                      save_name=save_name,\n",
    "                      ref_t = int(len(image_4D[ch_names[0]])/2),\n",
    "                      name_shifts=name_shifts,\n",
    "                      drift_corr=method)\n",
    "    \n",
    "    gfp_list = datautils.get_file_names(path=save_path, group_by=ch_names[0]+save_name, order=False, \n",
    "                                nested_files=False, criteria='tif')\n",
    "    gfp_4D = datautils.files_to_4D(files_list=gfp_list, ch_names=[ch_names[0]])\n",
    "    gfp_name = method+'_4D_'+ch_names[0]+'_'+group_by+'.tif'\n",
    "    datautils.save_image(gfp_name, gfp_4D, xy_pixel=0.0764616, z_pixel=0.4)\n",
    "    for file in gfp_list:\n",
    "        os.remove(file)\n",
    "\n",
    "    red_list = datautils.get_file_names(path=save_path, group_by=ch_names[1]+save_name, order=False, \n",
    "                                nested_files=False, criteria='tif')\n",
    "    red_4D = datautils.files_to_4D(files_list=red_list, ch_names=[ch_names[1]])\n",
    "    red_name = method+'_4D_'+ch_names[1]+'_'+group_by+'.tif'\n",
    "    datautils.save_image(red_name, red_4D, xy_pixel=0.0764616, z_pixel=0.4)\n",
    "    for file in red_list:\n",
    "        os.remove(file)\n",
    "    \n",
    "    # measuring the cosine_similarity check of GFP channel after registration\n",
    "    post_checks = datautils.similarity_4D(gfp_4D, save=True, \n",
    "                                            save_path=save_path, \n",
    "                                            save_file=method+'_checks.csv')\n",
    "\n",
    "    # deleting the final compiled 4D images\n",
    "    del gfp_4D, red_4D \n",
    "\n",
    "    print(method, ' is done, and it took', timer()-start_time)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
