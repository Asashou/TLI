{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read txt document of entry points\n",
    "# also iterate over all tif files (adult 3D mask images) in the same path and perform analysis \n",
    "# all analysis except column analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  input and save paths\n",
    "data_path = '/home/tli_project/Desktop/Data/T4/neurons/SubtypeB/'\n",
    "save_path = '/home/tli_project/Desktop/Data/T4/neurons/SubtypeB/output/'\n",
    "subtype = 'B'\n",
    "# stab_limit = 5 #(No. of timepoints for stable branches calculation)\n",
    "start_age = 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import utils.analysis as analysis\n",
    "import utils.datautils as datautils\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tif\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import math\n",
    "from skimage.measure import regionprops\n",
    "from read_roi import read_roi_zip as col_zip\n",
    "from scipy.spatial import ConvexHull, convex_hull_plot_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting list of folders in data_path, where each folder has files for one neuron\n",
    "N_folders = [name for name in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, name))]\n",
    "N_folders = [f for f in N_folders if '_P' in f]\n",
    "N_folders = sorted(N_folders)\n",
    "N_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading erntry_points file and converting it to dictionary of neu:[z,y,x]\n",
    "EP_file = '/home/tli_project/Desktop/Data/T4/neurons/TLI_stage1_entry_points'\n",
    "with open(EP_file) as f:\n",
    "    entry_points = f.readlines()\n",
    "entry_points = [l for l in entry_points if ': ' in l]\n",
    "entry_points = [l.rstrip('\\n').split(':') for l in entry_points]\n",
    "entry_points = {l[0]: l[1].split(',') for l in entry_points}\n",
    "entry_points = {neu:[int(x) for x in val] for neu,val in entry_points.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(n_file):\n",
    "    # neuron_results = pd.DataFrame(columns=results_cols)\n",
    "    entry_point = entry_points[n_file][1:] # remove the first T element\n",
    "    start_im = re.search('P(.*)_N', n_file)\n",
    "    start_im = float(start_im.group(1))\n",
    "    start_ana = int((start_age - start_im)/0.25)\n",
    "    files_list = datautils.get_file_names(data_path+n_file, group_by='', \n",
    "                                        order=True, nested_files=False, \n",
    "                                        criteria='')\n",
    "    neu_path = [f for f in files_list if 'clahe' in f.lower()][0]\n",
    "    neuron = tif.imread(neu_path)\n",
    "    mask_path = [f for f in files_list if 'mask' in f.lower()][0]\n",
    "    mask = tif.imread(mask_path)\n",
    "    neuron[mask==0] = 0\n",
    "    neuron = neuron[start_ana:] #remove timepoints before start_ana from the 4D image array\n",
    "    neuron[neuron != 0] = 1\n",
    "    cols_path = [f for f in files_list if 'colrois' in f.lower()][0]\n",
    "    Cols = col_zip(cols_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For explanation of the the individual columns in the result csv file, expand the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" Results\\' columns\\' description \\n\\'neuron\\':  neuron name extracted from file name\\n\\'subtype\\': neuron name extracted from file name\\n\\'entry_point\\': entry point of the neuron, read from seperate txt file\\n\\n\\'volume\\': number of pixels in the 3D masked image\\n\\'net_area\\': number of pixels in the 2D masked image (the 2D is a sum projection of the 3D image)\\n\\'area\\': area of the convex_hull surronding the 2D image (obtained from skimage.measure.regionprops)\\n\\'AP_spread\\': (max-min) of value pixels index in last (x) dimension of the 2D image\\n\\'DV_spread\\': (max-min) of value pixels index in (y) dimension of the 2D image\\n\\n\\'density_2D\\': solidity value obtained from skimage.measure.regionprops on the 2D image\\n\\'density_3D\\': pixel count of 3D image/pixel count of 3D convexhull \\n\\'object_perimeter\\': object perimenter value obtained from skimage.measure.regionprops on the 2D image\\n\\'convex_perimeter\\': perimeter of the surronding convex_hull\\n\\n\\'circularity\\': (4*np.pi*convex_area)/(convex_perimeter**2)\\n\\'compactness\\': object_perimeter**2/(4*np.pi*net_area)\\n\\'surface_area\\': mesh_surface_area of the marching_cubes on the 3D masked image\\n\\'eccentricity\\': eccentricity value obtained from skimage.measure.regionprops on the 2D image \\n>>>> change to 3D >>>>  \\'convexity\\': convex_perimeter/object_perimeter (maybe try surface_area/3D_image_convex_surface area)\\n\\'orientation\\': orientation value obtained from skimage.measure.regionprops on the 2D image \\n\\'feret_diameter_max\\': feret_diameter_max value obtained from skimage.measure.regionprops on the 2D image \\n\\'DGI\\':\\n\\n\\'centroidZ\\': Z position of the centroid from regionprops on the 3D masked image \\n\\'centroidY\\': Y position of the centroid from regionprops on the 3D masked image \\n\\'centroidX\\': X position of the centroid from regionprops on the 3D masked image \\n\\'cen_EP_dis\\': ecludian distance of the centroid from the entry point\\n\\'cen_EP_angle\\': angle of the line between centroid from the entry point (np.arctan2)\\n\\n£££ PCA analysis\\n\\'asymmetry\\':\\n\\'xP_weight\\', \\'xP_scale\\',\\'xP_angle\\',\\'xP_xy\\':\\n\\'xN_weight\\',\\'xN_scale\\',\\'xN_angle\\',\\'xN_xy\\',\\n\\'yP_weight\\',\\'yP_scale\\',\\'yP_angle\\',\\'yP_xy\\',\\n\\'yN_weight\\',\\'yN_scale\\',\\'yN_angle\\',\\'yN_xy\\',\\n\\'PCA_angle\\':\\n\\'PCA_xy\\':\\n\\'PCA_shift_centroid\\':\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\" Results' columns' description \n",
    "'neuron':  neuron name extracted from file name\n",
    "'subtype': neuron name extracted from file name\n",
    "'entry_point': entry point of the neuron, read from seperate txt file\n",
    "\n",
    "'volume': number of pixels in the 3D masked image\n",
    "'net_area': number of pixels in the 2D masked image (the 2D is a sum projection of the 3D image)\n",
    "'area': area of the convex_hull surronding the 2D image (obtained from skimage.measure.regionprops)\n",
    "'AP_spread': (max-min) of value pixels index in last (x) dimension of the 2D image\n",
    "'DV_spread': (max-min) of value pixels index in (y) dimension of the 2D image\n",
    "\n",
    "'density_2D': solidity value obtained from skimage.measure.regionprops on the 2D image\n",
    "'density_3D': pixel count of 3D image/pixel count of 3D convexhull \n",
    "'object_perimeter': object perimenter value obtained from skimage.measure.regionprops on the 2D image\n",
    "'convex_perimeter': perimeter of the surronding convex_hull\n",
    "\n",
    "'circularity': (4*np.pi*convex_area)/(convex_perimeter**2)\n",
    "'compactness': object_perimeter**2/(4*np.pi*net_area)\n",
    "'surface_area': mesh_surface_area of the marching_cubes on the 3D masked image\n",
    "'eccentricity': eccentricity value obtained from skimage.measure.regionprops on the 2D image \n",
    ">>>> change to 3D >>>>  'convexity': convex_perimeter/object_perimeter (maybe try surface_area/3D_image_convex_surface area)\n",
    "'orientation': orientation value obtained from skimage.measure.regionprops on the 2D image \n",
    "'feret_diameter_max': feret_diameter_max value obtained from skimage.measure.regionprops on the 2D image \n",
    "'DGI':\n",
    "\n",
    "'centroidZ': Z position of the centroid from regionprops on the 3D masked image \n",
    "'centroidY': Y position of the centroid from regionprops on the 3D masked image \n",
    "'centroidX': X position of the centroid from regionprops on the 3D masked image \n",
    "'cen_EP_dis': ecludian distance of the centroid from the entry point\n",
    "'cen_EP_angle': angle of the line between centroid from the entry point (np.arctan2)\n",
    "\n",
    "£££ PCA analysis\n",
    "'asymmetry':\n",
    "'xP_weight', 'xP_scale','xP_angle','xP_xy':\n",
    "'xN_weight','xN_scale','xN_angle','xN_xy',\n",
    "'yP_weight','yP_scale','yP_angle','yP_xy',\n",
    "'yN_weight','yN_scale','yN_angle','yN_xy',\n",
    "'PCA_angle':\n",
    "'PCA_xy':\n",
    "'PCA_shift_centroid':\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import tifffile as tif\n",
    "\n",
    "import utils.analysis as analysis\n",
    "import utils.datautils as datautils\n",
    "\n",
    "import numpy as np\n",
    "from skimage.measure import regionprops, marching_cubes, mesh_surface_area, perimeter\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import matplotlib.patches as mpatches\n",
    "# import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from multiprocessing import cpu_count, Process, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  input and save paths\n",
    "data_path = '/home/tli_project/Desktop/Data/T4/neurons/SubtypeB/'\n",
    "save_path = '/home/tli_project/Desktop/Data/T4/neurons/SubtypeB/output/'\n",
    "subtype = 'B'\n",
    "# stab_limit = 5 #(No. of timepoints for stable branches calculation)\n",
    "start_age = 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['211011_P37_N1', '211107_P36_N1']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting list of folders in data_path, where each folder has files for one neuron\n",
    "N_folders = [name for name in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, name))]\n",
    "N_folders = [f for f in N_folders if '_P' in f]\n",
    "N_folders = sorted(N_folders)\n",
    "N_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading erntry_points file and converting it to dictionary of neu:[z,y,x]\n",
    "EP_file = '/home/tli_project/Desktop/Data/T4/neurons/TLI_stage1_entry_points'\n",
    "with open(EP_file) as f:\n",
    "    entry_points = f.readlines()\n",
    "entry_points = [l for l in entry_points if ': ' in l]\n",
    "entry_points = [l.rstrip('\\n').split(':') for l in entry_points]\n",
    "entry_points = {l[0]: l[1].split(',') for l in entry_points}\n",
    "entry_points = {neu:[int(x) for x in val] for neu,val in entry_points.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cols = ['timepoint', 'volume', '3D_convex_volume', 'net_area', 'area',\n",
    "                'AP_spread', 'DV_spread',\n",
    "                'density_2D', 'density_3D', 'object_perimeter', 'convex_perimeter', \n",
    "                'circularity', 'compactness', 'surface_area', '3D_convex_surface',\n",
    "                'eccentricity', 'convexity_2D', 'convexity_3D', 'orientation',\n",
    "                'feret_diameter_max',\n",
    "                'DGI',\n",
    "                'centroidZ','centroidY', 'centroidX', \n",
    "                'cen_EP_dis', 'cen_EP_angle', 'cen_EP_Y','cen_EP_X',\n",
    "                'asymmetry', 'x_asymmetry', 'y_asymmetry', 'PC1_asymmetry', 'PC2_asymmetry',\n",
    "                'xP_weight','xP_scale','xP_angle','xP_xy', #all of this part is for the results from PCA_analysis\n",
    "                'xN_weight','xN_scale','xN_angle','xN_xy',\n",
    "                'yP_weight','yP_scale','yP_angle','yP_xy',\n",
    "                'yN_weight','yN_scale','yN_angle','yN_xy',\n",
    "                'PC1_angle','PC1_x','PC1_y']\n",
    "# results_df = pd.DataFrame(columns=results_cols)\n",
    "# for i in range(100):\n",
    "#     results_df.loc[start_age+i*0.25] = [None for col in results_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 5 files\n",
      "['/home/tli_project/Desktop/Data/T4/neurons/SubtypeB/211011_P37_N1/test_line.tif', '/home/tli_project/Desktop/Data/T4/neurons/SubtypeB/211011_P37_N1/original_cols_3.png', '/home/tli_project/Desktop/Data/T4/neurons/SubtypeB/211011_P37_N1/original_cols_2.png', '/home/tli_project/Desktop/Data/T4/neurons/SubtypeB/211011_P37_N1/original_cols_10.png', '/home/tli_project/Desktop/Data/T4/neurons/SubtypeB/211011_P37_N1/mywarpedgrid_3.png']\n"
     ]
    }
   ],
   "source": [
    "def process_image(n_file):\n",
    "    neuron_results = pd.DataFrame(columns=results_cols)\n",
    "    entry_point = entry_points[n_file][1:] # remove the first T element\n",
    "    start_im = re.search('P(.*)_N', n_file)\n",
    "    start_im = float(start_im.group(1))\n",
    "    start_ana = int((start_age - start_im)/0.25)\n",
    "    files_list = datautils.get_file_names(data_path+n_file, group_by='', \n",
    "                                        order=True, nested_files=False, \n",
    "                                        criteria='')\n",
    "    neu_path = [f for f in files_list if 'clahe' in f.lower()][0]\n",
    "    neuron = tif.imread(neu_path)\n",
    "    mask_path = [f for f in files_list if 'mask' in f.lower()][0]\n",
    "    mask = tif.imread(mask_path)\n",
    "    neuron[mask==0] = 0\n",
    "    neuron = neuron[start_ana:] #remove timepoints before start_ana from the 4D image array\n",
    "    neuron[neuron != 0] = 1\n",
    "    neu_2D = neuron.max(axis=1)\n",
    "    neuron_results['timepoint'] = [start_age+i*0.25 for i in range(len(neu_2D))]\n",
    "    neuron_results['volume'] = neuron.sum(axis=tuple(np.arange(len(neuron.shape))[1:]))\n",
    "    neuron_results['net_area'] = neu_2D.sum(axis=tuple(np.arange(len(neu_2D.shape))[1:]))\n",
    "    for t, stack in enumerate(neuron):\n",
    "        reg_prop_2D = regionprops(neu_2D[t])[0]\n",
    "        reg_prop_3D = regionprops(stack)[0]\n",
    "        neuron_results.loc[t,'density_2D'] = reg_prop_2D.solidity\n",
    "        neuron_results.loc[t,'area'] = reg_prop_2D.area_convex\n",
    "        neuron_results.loc[t,'orientation'] = reg_prop_2D.orientation\n",
    "        neuron_results.loc[t,'eccentricity'] = reg_prop_2D.eccentricity\n",
    "        neuron_results.loc[t,'feret_diameter_max'] = reg_prop_2D.feret_diameter_max\n",
    "        neuron_results.loc[t,'convex_perimeter'] = perimeter(reg_prop_2D.image_convex)\n",
    "        neuron_results.loc[t,'object_perimeter'] = reg_prop_2D.perimeter\n",
    "        neuron_results.loc[t,['centroidZ','centroidY','centroidX']] = reg_prop_3D.centroid\n",
    "        neuron_results.loc[t,'3D_convex_volume'] = reg_prop_3D.area_convex\n",
    "        neuron_results.loc[t,'density_3D'] = neuron_results.loc[t,'volume']/neuron_results.loc[t,'3D_convex_volume']\n",
    "        img_PC = reg_prop_3D.coords\n",
    "        neuron_results.loc[t,'DV_spread'] = (img_PC[:,1].max() - img_PC[:,1].min())*0.076\n",
    "        neuron_results.loc[t,'AP_spread'] = (img_PC[:,2].max() - img_PC[:,2].min())*0.076\n",
    "        centroid_EP = np.array(entry_point)-np.array(reg_prop_3D.centroid)\n",
    "        neuron_results.loc[t,'cen_EP_dis'] = np.linalg.norm(centroid_EP[1:])\n",
    "        neuron_results.loc[t,['cen_EP_Y','cen_EP_X']] = centroid_EP[1:]\n",
    "        p1 = (centroid_EP[1],centroid_EP[2])\n",
    "        neuron_results.loc[t,'cen_EP_angle'] = np.rad2deg((np.arctan2(*p1[::-1])) % (2 * np.pi))\n",
    "\n",
    "        verts, faces, normals, values = marching_cubes(stack, step_size=2, spacing=(0.4,0.076,0.076))\n",
    "        neuron_results.loc[t,'surface_area'] = mesh_surface_area(verts, faces)\n",
    "        convex_img_3D = reg_prop_3D.image_convex.astype('uint8')\n",
    "        verts, faces, normals, values = marching_cubes(convex_img_3D, step_size=2, spacing=(0.4,0.076,0.076))\n",
    "        neuron_results.loc[t,'3D_convex_surface'] = mesh_surface_area(verts, faces)\n",
    "        neuron_results.loc[t,'convexity_3D'] = neuron_results.loc[t,'3D_convex_surface']/neuron_results.loc[t,'surface_area']\n",
    "\n",
    "        asymmetry_values, PCA_df, shifted_coor = analysis.metric_dump(neu_2D[t],entry_point[1:],plot=False)\n",
    "        asymmetries = ['asymmetry', 'x_asymmetry', 'y_asymmetry', 'PC1_asymmetry', 'PC2_asymmetry']\n",
    "        neuron_results.loc[t,asymmetries]  = asymmetry_values\n",
    "\n",
    "        PCA_res = ['xP_weight','xP_scale','xP_angle','xP_xy',\n",
    "                    'xN_weight','xN_scale','xN_angle','xN_xy',\n",
    "                    'yP_weight','yP_scale','yP_angle','yP_xy',\n",
    "                    'yN_weight','yN_scale','yN_angle','yN_xy']\n",
    "        PCA_arr = np.array(PCA_df.loc[:, PCA_df.columns != 'axis'])\n",
    "        neuron_results.loc[t,PCA_res]  = PCA_arr.ravel()\n",
    "        neuron_results.loc[t,'PC1_angle'] = PCA_df.loc[PCA_df.Fraction_weight.idxmax()].Angle\n",
    "        neuron_results.loc[t,'PC1_x'] = PCA_df.loc[PCA_df.Fraction_weight.idxmax()].xy[0]\n",
    "        neuron_results.loc[t,'PC1_y'] = PCA_df.loc[PCA_df.Fraction_weight.idxmax()].xy[1]\n",
    "        # neuron_results.loc[t,'PC1_shift_centroid'] = (sum(shifted_coor[:,1]) / len(shifted_coor), sum(shifted_coor[:,0]) / len(shifted_coor))\n",
    "        \n",
    "        neuron_results.loc[t,'DGI'] = analysis.DGI_3D(stack,entry_point)\n",
    "\n",
    "    neuron_results['convexity_2D'] = neuron_results['convex_perimeter']/neuron_results['object_perimeter']\n",
    "    neuron_results['circularity'] = (4*np.pi*neuron_results['area'])/(neuron_results['convex_perimeter']**2)\n",
    "    neuron_results['compactness'] = neuron_results['object_perimeter']#     p = Pool(cpu_count()-1)\n",
    "    csv_name = save_path+n_file+'_s'+subtype+'.csv'\n",
    "    neuron_results.to_csv(csv_name)\n",
    "    return neuron_results\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # c = cpu_count()-1\n",
    "#     with Pool(3) as p:\n",
    "#         p.map(process_image, N_folders)\n",
    "\n",
    "for n_file in tqdm(N_folders):\n",
    "    process_image(n_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, n_file in tqdm(enumerate(N_folders)):\n",
    "#     neuron_results = pd.DataFrame(columns=results_cols)\n",
    "#     entry_point = entry_points[n_file][1:]\n",
    "#     start_im = re.search('P(.*)_N', n_file)\n",
    "#     start_im = float(start_im.group(1))\n",
    "#     start_ana = int((start_age - start_im)/0.25)\n",
    "#     files_list = datautils.get_file_names(data_path+n_file, group_by='', \n",
    "#                                         order=True, nested_files=False, \n",
    "#                                         criteria='')\n",
    "#     neu_path = [f for f in files_list if 'clahe' in f.lower()][0]\n",
    "#     neuron = tif.imread(neu_path)\n",
    "#     mask_path = [f for f in files_list if 'mask' in f.lower()][0]\n",
    "#     mask = tif.imread(mask_path)\n",
    "#     neuron[mask==0] = 0\n",
    "#     neuron = neuron[start_ana:] #remove timepoints before start_ana from the 4D image array\n",
    "#     neuron[neuron != 0] = 1\n",
    "#     neu_2D = neuron.max(axis=1)\n",
    "#     neu_2D = neuron.max(axis=1)\n",
    "#     neuron_results['timepoint'] = [start_age+i*0.25 for i in range(len(neu_2D))]\n",
    "#     neuron_results['volume'] = neuron.sum(axis=tuple(np.arange(len(neuron.shape))[1:]))\n",
    "#     neuron_results['net_area'] = neu_2D.sum(axis=tuple(np.arange(len(neu_2D.shape))[1:]))\n",
    "\n",
    "#     reg_prop_2D = []\n",
    "#     reg_prop_3D = []\n",
    "#     for t, stack in enumerate(neuron):\n",
    "#         reg_prop_2D.append(regionprops(neu_2D[t])[0])\n",
    "#         reg_prop_3D.append(regionprops(stack)[0])\n",
    "#         img_PC = reg_prop_3D[t].coords\n",
    "#         neuron_results.loc[t,'DV_spread'] = (img_PC[:,1].max() - img_PC[:,1].min())*0.076\n",
    "#         neuron_results.loc[t,'AP_spread'] = (img_PC[:,2].max() - img_PC[:,2].min())*0.076\n",
    "#         neuron_results.loc[t,'density_3D'] = neuron_results.loc[t,'volume']/regionprops(stack)[0].area_convex\n",
    "\n",
    "#         verts, faces, normals, values = marching_cubes(stack, step_size=2, spacing=(0.4,0.076,0.076))\n",
    "#         neuron_results.loc[t,'surface_area'] = mesh_surface_area(verts, faces)\n",
    "#         convex_img_3D = reg_prop_3D[t].image_convex.astype('uint8')\n",
    "#         verts, faces, normals, values = marching_cubes(convex_img_3D, step_size=2, spacing=(0.4,0.076,0.076))\n",
    "#         neuron_results.loc[t,'convexity_3D'] = mesh_surface_area(verts, faces)/neuron_results.loc[t,'surface_area']\n",
    "\n",
    "#         asymmetry_values, PCA_df, shifted_coor = analysis.metric_dump(neu_2D[t],entry_point[1:],plot=False)\n",
    "#         asymmetries = ['asymmetry', 'x_asymmetry', 'y_asymmetry', 'PC1_asymmetry', 'PC2_asymmetry']\n",
    "#         neuron_results.loc[t,asymmetries]  = asymmetry_values\n",
    "\n",
    "#         PCA_res = ['xP_weight','xP_scale','xP_angle','xP_xy',\n",
    "#                     'xN_weight','xN_scale','xN_angle','xN_xy',\n",
    "#                     'yP_weight','yP_scale','yP_angle','yP_xy',\n",
    "#                     'yN_weight','yN_scale','yN_angle','yN_xy']\n",
    "#         PCA_arr = np.array(PCA_df.loc[:, PCA_df.columns != 'axis'])\n",
    "#         neuron_results.loc[t,PCA_res]  = PCA_arr.ravel()\n",
    "#         neuron_results.loc[t,'PC1_angle'] = PCA_df.loc[PCA_df.Fraction_weight.idxmax()].Angle\n",
    "#         neuron_results.loc[t,'PC1_x'] = PCA_df.loc[PCA_df.Fraction_weight.idxmax()].xy[0]\n",
    "#         neuron_results.loc[t,'PC1_y'] = PCA_df.loc[PCA_df.Fraction_weight.idxmax()].xy[1]\n",
    "\n",
    "#         neuron_results.loc[t,['centroidZ','centroidY','centroidX']] = reg_prop_3D[t].centroid\n",
    "#         centroid_EP = np.array(entry_point)-np.array(reg_prop_3D[t].centroid)\n",
    "#         neuron_results.loc[t,'cen_EP_dis'] = np.linalg.norm(centroid_EP[1:])\n",
    "#         neuron_results.loc[t,['cen_EP_Y','cen_EP_X']] = centroid_EP[1:]\n",
    "#         p1 = (centroid_EP[1],centroid_EP[2])\n",
    "#         neuron_results.loc[t,'cen_EP_angle'] = np.rad2deg((np.arctan2(*p1[::-1])) % (2 * np.pi))\n",
    "\n",
    "\n",
    "#     del neuron, neu_2D\n",
    "#     neuron_results['density_2D'] = [r.solidity for r in reg_prop_2D]\n",
    "#     # neuron_results['density_3D'] = [r.area_convex for r in reg_prop_3D]\n",
    "#     # neuron_results['density_3D'] = neuron_results.loc[t,'volume']/neuron_results['density_3D']\n",
    "#     neuron_results['area'] = [r.area_convex for r in reg_prop_2D]\n",
    "#     neuron_results['orientation'] = [r.orientation for r in reg_prop_2D]\n",
    "#     neuron_results['eccentricity'] = [r.eccentricity for r in reg_prop_2D]\n",
    "#     neuron_results['feret_diameter_max'] = [r.feret_diameter_max for r in reg_prop_2D]\n",
    "#     neuron_results['convex_perimeter'] = [perimeter(r.image_convex) for r in reg_prop_2D]\n",
    "#     neuron_results['object_perimeter'] = [r.perimeter for r in reg_prop_2D]\n",
    "#     neuron_results['convexity_2D'] = neuron_results['convex_perimeter']/neuron_results['object_perimeter']\n",
    "#     neuron_results['circularity'] = (4*np.pi*neuron_results['area'])/(neuron_results['convex_perimeter']**2)\n",
    "#     neuron_results['compactness'] = neuron_results['object_perimeter']**2/(4*np.pi*neuron_results['net_area'])\n",
    "#     del reg_prop_2D, reg_prop_3D\n",
    "\n",
    "#     csv_name = save_path+n_file+'_s'+subtype+'_new_111.csv'\n",
    "#     neuron_results.to_csv(csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e774977668b7c0ae8309835a5187aa7fbf7669e7d0bb59755bc63e573643edcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
